# å¤§æ¨¡å‹å¼•æ“
from openai import OpenAI
from config import Config


class LLMEngine:
    def __init__(self):
        self.client = OpenAI(
            api_key=Config.API_KEY,
            base_url=Config.API_BASE_URL
        )

    def generate_reply(self, input_text, sentiment):
        """
        å‘é€è¯·æ±‚ç»™å¤§æ¨¡å‹å¹¶è¿”å›æ–‡æœ¬
        """
        prompt = f"""
        æˆ‘æ˜¯ä¸€ä¸ªä¸å–„è¨€è¾çš„äººï¼Œå¯¹æ–¹å‘æ¥ï¼šâ€œ{input_text}â€
        æˆ‘çš„åˆ†æç¨‹åºåˆ¤æ–­è¯­æ°”ä¸ºï¼šã€{sentiment}ã€‘ã€‚
        
        è¯·ç”Ÿæˆ 3 æ¡å›å¤å»ºè®®ï¼ˆåˆ†åˆ«å¯¹åº”ï¼š1.å¾—ä½“ç¤¼è²Œ 2.çƒ­æƒ…é«˜æƒ…å•† 3.æœºæ™ºé˜²å¾¡ï¼‰ã€‚
        
        âš ï¸ æ ¼å¼ä¸¥æ ¼è¦æ±‚ï¼š
        1. ä¸è¦è¾“å‡ºä»»ä½•å¼€åœºç™½ã€åºå·æˆ–ç»“æŸè¯­ã€‚
        2. ä»…è¾“å‡º3æ¡å…·ä½“å›å¤å†…å®¹ã€‚
        3. 3æ¡å†…å®¹ä¹‹é—´ä½¿ç”¨ "|||" ç¬¦å·åˆ†éš”ã€‚
        
        ä¾‹å¦‚ï¼š
        å¥½çš„ï¼Œæ˜ç™½äº†|||å“‡ï¼Œè¿™éƒ½è¢«ä½ å‘ç°äº†|||ä¹Ÿå°±æ˜¯é‚£æ ·å§
        """

        try:
            response = self.client.chat.completions.create(
                model=Config.MODEL_NAME,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸¥æ ¼éµå®ˆæ ¼å¼æŒ‡ä»¤çš„è¾…åŠ©ç¨‹åºã€‚"},
                    {"role": "user", "content": prompt},
                ],
                temperature=0.7
            )
            raw_text = response.choices[0].message.content.strip()

            # ğŸ’¡ è§£æé€»è¾‘ï¼šæŠŠé•¿å­—ç¬¦ä¸²åˆ‡åˆ†æˆåˆ—è¡¨
            # å¦‚æœ AI æ²¡å¬è¯ï¼Œæ²¡ç”¨ ||| åˆ†éš”ï¼Œæˆ‘ä»¬å°±æŒ‰æ¢è¡Œç¬¦å¼ºè¡Œåˆ‡
            if "|||" in raw_text:
                replies = raw_text.split("|||")
            else:
                replies = raw_text.split("\n")

            # æ¸…ç†ä¸€ä¸‹æ¯æ¡å›å¤çš„å‰åç©ºæ ¼ï¼Œå¹¶è¿‡æ»¤ç©ºè¡Œ
            clean_replies = [r.strip() for r in replies if r.strip()]

            # ç¡®ä¿åªæœ‰3æ¡ï¼Œå¤šä½™çš„ä¸è¦ï¼Œå°‘äº†è¡¥ç©º
            return clean_replies[:3]

        except Exception as e:
            return f"API è°ƒç”¨å¤±è´¥: {str(e)}"