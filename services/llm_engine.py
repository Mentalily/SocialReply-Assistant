# å¤§æ¨¡å‹å¼•æ“
from openai import OpenAI
from config import Config


class LLMEngine:
    def __init__(self):
        self.client = OpenAI(
            api_key=Config.API_KEY,
            base_url=Config.API_BASE_URL
        )

    def generate_reply(self, input_text, sentiment):
        """
        å‘é€è¯·æ±‚ç»™å¤§æ¨¡å‹å¹¶è¿”å›æ–‡æœ¬
        """
        prompt = f"""
        æˆ‘æ˜¯ä¸€ä¸ªä¸å–„è¨€è¾çš„äººï¼Œç°åœ¨å¯¹æ–¹å‘æ¥ä¸€å¥è¯ï¼š
        â€œ{input_text}â€
        æˆ‘çš„æƒ…æ„Ÿåˆ†æç¨‹åºåˆ¤æ–­è¿™å¥è¯çš„è¯­æ°”æ˜¯ï¼šã€{sentiment}ã€‘ã€‚

        è¯·åšæˆ‘çš„â€œé«˜æƒ…å•†å˜´æ›¿â€ï¼Œå¸®æˆ‘ç”Ÿæˆ 3 æ¡ä¸åŒé£æ ¼çš„å›å¤å»ºè®®ï¼š
        1. ğŸ¤ ã€å¾—ä½“/ç¤¼è²Œã€‘
        2. ğŸ”¥ ã€çƒ­æƒ…/é«˜æƒ…å•†ã€‘
        3. ğŸ›¡ï¸ ã€æœºæ™º/é˜²å¾¡ã€‘
        """

        try:
            response = self.client.chat.completions.create(
                model=Config.MODEL_NAME,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªé«˜æƒ…å•†ç¤¾äº¤åŠ©æ‰‹ã€‚"},
                    {"role": "user", "content": prompt},
                ],
                temperature=0.7
            )
            return response.choices[0].message.content
        except Exception as e:
            return f"API è°ƒç”¨å¤±è´¥: {str(e)}"